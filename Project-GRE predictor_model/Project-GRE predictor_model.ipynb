{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c9168718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "728d90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=pd.read_csv('Admission_Predict_Ver1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "61dddd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "495         496        332          108                  5  4.5   4.0  9.02   \n",
       "496         497        337          117                  5  5.0   5.0  9.87   \n",
       "497         498        330          120                  5  4.5   5.0  9.56   \n",
       "498         499        312          103                  4  4.0   5.0  8.43   \n",
       "499         500        327          113                  4  4.5   4.5  9.04   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "495         1              0.87  \n",
       "496         1              0.96  \n",
       "497         1              0.93  \n",
       "498         0              0.73  \n",
       "499         0              0.84  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9069483a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4b2c7d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4e8a9c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1655164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.drop(columns=['Serial No.'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b9e0006a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0          337          118                  4  4.5   4.5  9.65         1   \n",
       "1          324          107                  4  4.0   4.5  8.87         1   \n",
       "2          316          104                  3  3.0   3.5  8.00         1   \n",
       "3          322          110                  3  3.5   2.5  8.67         1   \n",
       "4          314          103                  2  2.0   3.0  8.21         0   \n",
       "..         ...          ...                ...  ...   ...   ...       ...   \n",
       "495        332          108                  5  4.5   4.0  9.02         1   \n",
       "496        337          117                  5  5.0   5.0  9.87         1   \n",
       "497        330          120                  5  4.5   5.0  9.56         1   \n",
       "498        312          103                  4  4.0   5.0  8.43         0   \n",
       "499        327          113                  4  4.5   4.5  9.04         0   \n",
       "\n",
       "     Chance of Admit   \n",
       "0                0.92  \n",
       "1                0.76  \n",
       "2                0.72  \n",
       "3                0.80  \n",
       "4                0.65  \n",
       "..                ...  \n",
       "495              0.87  \n",
       "496              0.96  \n",
       "497              0.93  \n",
       "498              0.73  \n",
       "499              0.84  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3c852848",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=file.iloc[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "078c04f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=file.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a215c654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "495        332          108                  5  4.5   4.0  9.02         1\n",
       "496        337          117                  5  5.0   5.0  9.87         1\n",
       "497        330          120                  5  4.5   5.0  9.56         1\n",
       "498        312          103                  4  4.0   5.0  8.43         0\n",
       "499        327          113                  4  4.5   4.5  9.04         0\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c65240ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "495    0.87\n",
       "496    0.96\n",
       "497    0.93\n",
       "498    0.73\n",
       "499    0.84\n",
       "Name: Chance of Admit , Length: 500, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e4480504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e5818711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>310</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>318</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>300</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>300</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>322</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>307</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>326</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>300</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "238        310          104                  3  2.0   3.5  8.37         0\n",
       "438        318          110                  1  2.5   3.5  8.54         1\n",
       "475        300          101                  3  3.5   2.5  7.88         0\n",
       "58         300           99                  1  3.0   2.0  6.80         1\n",
       "380        322          104                  3  3.5   4.0  8.84         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "255        307          110                  4  4.0   4.5  8.37         0\n",
       "72         321          111                  5  5.0   5.0  9.45         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "235        326          111                  5  4.5   4.0  9.23         1\n",
       "37         300          105                  1  1.0   2.0  7.80         0\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ccfb3d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>313</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>312</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>339</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>316</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>325</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>327</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>322</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>298</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>316</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>305</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "304        313          106                  2  2.5   2.0  8.43         0\n",
       "340        312          107                  3  3.0   3.0  8.46         1\n",
       "47         339          119                  5  4.5   4.0  9.70         0\n",
       "67         316          107                  2  3.5   3.5  8.64         1\n",
       "479        325          110                  4  4.5   4.0  8.96         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "11         327          111                  4  4.0   4.5  9.00         1\n",
       "192        322          114                  5  4.5   4.0  8.94         1\n",
       "92         298           98                  2  4.0   3.0  8.03         0\n",
       "221        316          110                  3  3.5   4.0  8.56         0\n",
       "110        305          108                  5  3.0   3.0  8.48         0\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "11ce9000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "76b71876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eba664d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "de8cc2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled=scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fc0ba6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scaled=scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b003fe18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.42857143, 0.5       , ..., 0.57142857, 0.50320513,\n",
       "        0.        ],\n",
       "       [0.56      , 0.64285714, 0.        , ..., 0.57142857, 0.55769231,\n",
       "        1.        ],\n",
       "       [0.2       , 0.32142857, 0.5       , ..., 0.28571429, 0.34615385,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.74038462,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.77884615,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.32051282,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "363bed4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46      , 0.48      , 0.25      , 0.375     , 0.25      ,\n",
       "        0.44140625, 0.        ],\n",
       "       [0.44      , 0.52      , 0.5       , 0.5       , 0.5       ,\n",
       "        0.453125  , 1.        ],\n",
       "       [0.98      , 1.        , 1.        , 0.875     , 0.75      ,\n",
       "        0.9375    , 0.        ],\n",
       "       [0.52      , 0.52      , 0.25      , 0.625     , 0.625     ,\n",
       "        0.5234375 , 1.        ],\n",
       "       [0.7       , 0.64      , 0.75      , 0.875     , 0.75      ,\n",
       "        0.6484375 , 1.        ],\n",
       "       [0.42      , 0.28      , 0.25      , 0.375     , 0.625     ,\n",
       "        0.40625   , 1.        ],\n",
       "       [0.6       , 0.4       , 0.5       , 0.5       , 0.625     ,\n",
       "        0.5625    , 1.        ],\n",
       "       [0.74      , 0.36      , 0.5       , 0.75      , 0.75      ,\n",
       "        0.390625  , 1.        ],\n",
       "       [0.62      , 0.68      , 0.5       , 0.625     , 0.75      ,\n",
       "        0.59765625, 1.        ],\n",
       "       [0.56      , 0.48      , 0.25      , 0.75      , 0.75      ,\n",
       "        0.2421875 , 1.        ],\n",
       "       [0.48      , 0.52      , 0.25      , 0.375     , 0.75      ,\n",
       "        0.37890625, 0.        ],\n",
       "       [0.06      , 0.12      , 0.25      , 0.25      , 0.75      ,\n",
       "        0.1953125 , 1.        ],\n",
       "       [0.74      , 0.4       , 1.        , 0.5       , 0.625     ,\n",
       "        0.6015625 , 1.        ],\n",
       "       [0.74      , 0.8       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.671875  , 0.        ],\n",
       "       [0.62      , 0.6       , 0.5       , 0.625     , 0.625     ,\n",
       "        0.5859375 , 1.        ],\n",
       "       [0.68      , 0.72      , 1.        , 1.        , 1.        ,\n",
       "        0.6953125 , 1.        ],\n",
       "       [0.32      , 0.36      , 0.5       , 0.625     , 0.5       ,\n",
       "        0.35546875, 0.        ],\n",
       "       [0.46      , 0.6       , 0.5       , 0.75      , 0.625     ,\n",
       "        0.6640625 , 0.        ],\n",
       "       [0.82      , 0.84      , 1.        , 0.75      , 0.625     ,\n",
       "        0.8359375 , 1.        ],\n",
       "       [0.5       , 0.44      , 0.5       , 0.25      , 0.375     ,\n",
       "        0.4609375 , 0.        ],\n",
       "       [0.44      , 0.16      , 0.        , 0.625     , 0.5       ,\n",
       "        0.34375   , 1.        ],\n",
       "       [0.42      , 0.52      , 0.75      , 0.875     , 0.875     ,\n",
       "        0.6640625 , 1.        ],\n",
       "       [0.76      , 0.56      , 0.75      , 0.875     , 0.75      ,\n",
       "        0.734375  , 1.        ],\n",
       "       [0.16      , 0.28      , 0.75      , 0.375     , 0.875     ,\n",
       "        0.15234375, 1.        ],\n",
       "       [0.7       , 0.72      , 0.75      , 0.625     , 0.625     ,\n",
       "        0.6328125 , 0.        ],\n",
       "       [0.5       , 0.44      , 0.25      , 0.25      , 0.375     ,\n",
       "        0.13671875, 0.        ],\n",
       "       [0.82      , 0.72      , 1.        , 0.75      , 1.        ,\n",
       "        0.9765625 , 1.        ],\n",
       "       [0.36      , 0.48      , 0.5       , 0.5       , 0.5       ,\n",
       "        0.3671875 , 0.        ],\n",
       "       [0.66      , 0.76      , 0.75      , 0.75      , 0.875     ,\n",
       "        0.75390625, 1.        ],\n",
       "       [0.5       , 0.64      , 0.25      , 0.625     , 0.5       ,\n",
       "        0.453125  , 1.        ],\n",
       "       [0.34      , 0.32      , 0.5       , 0.5       , 0.5       ,\n",
       "        0.37890625, 0.        ],\n",
       "       [0.66      , 0.64      , 0.5       , 0.75      , 0.625     ,\n",
       "        0.703125  , 1.        ],\n",
       "       [0.28      , 0.24      , 0.25      , 0.375     , 0.625     ,\n",
       "        0.30078125, 0.        ],\n",
       "       [0.82      , 0.88      , 0.75      , 0.875     , 0.875     ,\n",
       "        0.8359375 , 1.        ],\n",
       "       [0.52      , 0.16      , 0.        , 0.125     , 0.25      ,\n",
       "        0.05078125, 0.        ],\n",
       "       [0.72      , 0.72      , 0.5       , 0.625     , 0.5       ,\n",
       "        0.703125  , 1.        ],\n",
       "       [0.6       , 0.28      , 0.25      , 0.375     , 0.5       ,\n",
       "        0.515625  , 0.        ],\n",
       "       [0.48      , 0.36      , 0.25      , 0.25      , 0.5       ,\n",
       "        0.35546875, 0.        ],\n",
       "       [0.5       , 0.44      , 0.25      , 0.5       , 0.5       ,\n",
       "        0.40625   , 0.        ],\n",
       "       [0.88      , 0.88      , 0.75      , 0.75      , 0.625     ,\n",
       "        0.875     , 1.        ],\n",
       "       [0.18      , 0.24      , 0.5       , 0.25      , 0.25      ,\n",
       "        0.28125   , 0.        ],\n",
       "       [0.42      , 0.4       , 0.5       , 0.75      , 0.625     ,\n",
       "        0.32421875, 1.        ],\n",
       "       [0.56      , 0.28      , 1.        , 0.625     , 1.        ,\n",
       "        0.578125  , 1.        ],\n",
       "       [0.86      , 1.        , 1.        , 1.        , 0.875     ,\n",
       "        0.96875   , 1.        ],\n",
       "       [0.74      , 0.76      , 0.5       , 0.625     , 0.5       ,\n",
       "        0.53125   , 1.        ],\n",
       "       [0.14      , 0.08      , 0.25      , 0.375     , 0.125     ,\n",
       "        0.23046875, 0.        ],\n",
       "       [0.54      , 0.24      , 0.25      , 0.5       , 0.375     ,\n",
       "        0.49609375, 0.        ],\n",
       "       [0.5       , 0.4       , 0.5       , 0.75      , 0.375     ,\n",
       "        0.3125    , 0.        ],\n",
       "       [0.64      , 0.36      , 0.75      , 0.5       , 0.375     ,\n",
       "        0.28125   , 1.        ],\n",
       "       [0.48      , 0.48      , 0.25      , 0.75      , 0.625     ,\n",
       "        0.37109375, 0.        ],\n",
       "       [0.78      , 0.68      , 0.75      , 0.875     , 0.75      ,\n",
       "        0.66796875, 1.        ],\n",
       "       [0.82      , 0.92      , 0.75      , 0.875     , 1.        ,\n",
       "        0.828125  , 1.        ],\n",
       "       [0.8       , 0.84      , 1.        , 0.875     , 0.5       ,\n",
       "        0.796875  , 1.        ],\n",
       "       [0.36      , 0.32      , 0.25      , 0.25      , 0.625     ,\n",
       "        0.265625  , 1.        ],\n",
       "       [0.5       , 0.28      , 0.5       , 0.625     , 0.875     ,\n",
       "        0.71484375, 0.        ],\n",
       "       [0.28      , 0.44      , 0.25      , 0.5       , 0.5       ,\n",
       "        0.3515625 , 1.        ],\n",
       "       [0.44      , 0.52      , 0.75      , 0.875     , 0.75      ,\n",
       "        0.52734375, 1.        ],\n",
       "       [0.38      , 0.48      , 0.25      , 0.375     , 0.375     ,\n",
       "        0.2734375 , 0.        ],\n",
       "       [0.58      , 0.48      , 0.5       , 0.75      , 0.5       ,\n",
       "        0.2734375 , 1.        ],\n",
       "       [0.56      , 0.52      , 0.5       , 0.5       , 0.625     ,\n",
       "        0.37890625, 1.        ],\n",
       "       [0.18      , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.015625  , 0.        ],\n",
       "       [0.58      , 0.36      , 0.75      , 0.875     , 0.625     ,\n",
       "        0.53125   , 0.        ],\n",
       "       [0.68      , 0.24      , 0.5       , 0.75      , 1.        ,\n",
       "        0.5234375 , 1.        ],\n",
       "       [0.8       , 0.8       , 0.75      , 0.875     , 0.5       ,\n",
       "        0.73046875, 1.        ],\n",
       "       [0.9       , 0.92      , 1.        , 1.        , 1.        ,\n",
       "        0.984375  , 1.        ],\n",
       "       [0.36      , 0.4       , 0.25      , 0.375     , 0.5       ,\n",
       "        0.30078125, 0.        ],\n",
       "       [0.6       , 0.56      , 0.5       , 0.625     , 0.75      ,\n",
       "        0.4453125 , 1.        ],\n",
       "       [0.68      , 0.52      , 1.        , 0.625     , 0.75      ,\n",
       "        0.53125   , 1.        ],\n",
       "       [1.        , 0.72      , 0.75      , 1.        , 0.875     ,\n",
       "        0.921875  , 1.        ],\n",
       "       [0.56      , 0.6       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.46875   , 0.        ],\n",
       "       [0.3       , 0.32      , 0.25      , 0.25      , 0.375     ,\n",
       "        0.34375   , 0.        ],\n",
       "       [0.5       , 0.4       , 0.5       , 0.5       , 0.375     ,\n",
       "        0.40234375, 0.        ],\n",
       "       [0.72      , 0.8       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.70703125, 1.        ],\n",
       "       [0.4       , 0.2       , 0.25      , 0.125     , 0.25      ,\n",
       "        0.        , 0.        ],\n",
       "       [0.96      , 0.92      , 0.75      , 0.625     , 0.875     ,\n",
       "        0.84375   , 1.        ],\n",
       "       [0.28      , 0.52      , 0.5       , 0.625     , 0.5       ,\n",
       "        0.21875   , 0.        ],\n",
       "       [0.84      , 0.56      , 1.        , 0.875     , 0.75      ,\n",
       "        0.671875  , 1.        ],\n",
       "       [0.66      , 0.68      , 1.        , 0.75      , 1.        ,\n",
       "        1.        , 1.        ],\n",
       "       [0.6       , 0.4       , 0.5       , 0.5       , 0.375     ,\n",
       "        0.49609375, 1.        ],\n",
       "       [0.48      , 0.6       , 0.75      , 0.625     , 0.75      ,\n",
       "        0.57421875, 1.        ],\n",
       "       [0.74      , 0.56      , 1.        , 1.        , 0.625     ,\n",
       "        0.71484375, 1.        ],\n",
       "       [0.        , 0.4       , 0.75      , 0.25      , 0.375     ,\n",
       "        0.0625    , 0.        ],\n",
       "       [0.9       , 0.96      , 1.        , 0.875     , 0.625     ,\n",
       "        0.8359375 , 1.        ],\n",
       "       [0.74      , 0.48      , 0.75      , 0.75      , 0.875     ,\n",
       "        0.56640625, 1.        ],\n",
       "       [0.64      , 0.64      , 1.        , 0.875     , 0.75      ,\n",
       "        0.65234375, 0.        ],\n",
       "       [0.36      , 0.6       , 0.25      , 0.5       , 0.75      ,\n",
       "        0.44921875, 0.        ],\n",
       "       [0.68      , 0.76      , 1.        , 0.75      , 1.        ,\n",
       "        0.76171875, 1.        ],\n",
       "       [0.82      , 0.88      , 1.        , 0.75      , 0.75      ,\n",
       "        0.765625  , 1.        ],\n",
       "       [0.14      , 0.2       , 0.75      , 0.5       , 0.625     ,\n",
       "        0.19921875, 0.        ],\n",
       "       [0.28      , 0.4       , 0.5       , 0.375     , 0.25      ,\n",
       "        0.3203125 , 0.        ],\n",
       "       [0.38      , 0.44      , 0.75      , 0.625     , 0.25      ,\n",
       "        0.34375   , 0.        ],\n",
       "       [0.62      , 0.32      , 0.5       , 0.625     , 0.75      ,\n",
       "        0.66796875, 1.        ],\n",
       "       [0.52      , 0.36      , 0.5       , 0.625     , 0.25      ,\n",
       "        0.1484375 , 0.        ],\n",
       "       [0.62      , 0.6       , 0.5       , 0.5       , 0.75      ,\n",
       "        0.3515625 , 1.        ],\n",
       "       [0.64      , 0.72      , 0.75      , 0.625     , 0.375     ,\n",
       "        0.671875  , 1.        ],\n",
       "       [0.74      , 0.68      , 0.75      , 0.75      , 0.875     ,\n",
       "        0.6640625 , 1.        ],\n",
       "       [0.64      , 0.8       , 1.        , 0.875     , 0.75      ,\n",
       "        0.640625  , 1.        ],\n",
       "       [0.16      , 0.16      , 0.25      , 0.75      , 0.5       ,\n",
       "        0.28515625, 0.        ],\n",
       "       [0.52      , 0.64      , 0.5       , 0.625     , 0.75      ,\n",
       "        0.4921875 , 0.        ],\n",
       "       [0.3       , 0.56      , 1.        , 0.5       , 0.5       ,\n",
       "        0.4609375 , 0.        ]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bfd16fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "30334b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "19a759c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "98b1bfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b7915257",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='mean_squared_error',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "65230d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 1s 45ms/step - loss: 4.2532 - accuracy: 0.0000e+00 - val_loss: 4.0491 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.4768 - accuracy: 0.0000e+00 - val_loss: 3.2825 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2.8281 - accuracy: 0.0000e+00 - val_loss: 2.6777 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2.3206 - accuracy: 0.0000e+00 - val_loss: 2.1962 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.9201 - accuracy: 0.0000e+00 - val_loss: 1.8172 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.5982 - accuracy: 0.0000e+00 - val_loss: 1.5236 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.3463 - accuracy: 0.0000e+00 - val_loss: 1.2916 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.1493 - accuracy: 0.0000e+00 - val_loss: 1.1060 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9899 - accuracy: 0.0000e+00 - val_loss: 0.9528 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8568 - accuracy: 0.0000e+00 - val_loss: 0.8223 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7408 - accuracy: 0.0000e+00 - val_loss: 0.7067 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6377 - accuracy: 0.0000e+00 - val_loss: 0.5978 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5402 - accuracy: 0.0000e+00 - val_loss: 0.4860 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4385 - accuracy: 0.0000e+00 - val_loss: 0.3757 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3337 - accuracy: 0.0000e+00 - val_loss: 0.2747 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2410 - accuracy: 0.0000e+00 - val_loss: 0.1895 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1669 - accuracy: 0.0000e+00 - val_loss: 0.1259 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1123 - accuracy: 0.0000e+00 - val_loss: 0.0850 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0789 - accuracy: 0.0000e+00 - val_loss: 0.0631 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0604 - accuracy: 0.0000e+00 - val_loss: 0.0534 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0511 - accuracy: 0.0000e+00 - val_loss: 0.0485 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0459 - accuracy: 0.0000e+00 - val_loss: 0.0448 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0415 - accuracy: 0.0000e+00 - val_loss: 0.0406 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0378 - accuracy: 0.0000e+00 - val_loss: 0.0367 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0345 - accuracy: 0.0000e+00 - val_loss: 0.0331 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0316 - accuracy: 0.0000e+00 - val_loss: 0.0302 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0290 - accuracy: 0.0000e+00 - val_loss: 0.0277 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0268 - accuracy: 0.0000e+00 - val_loss: 0.0256 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0247 - accuracy: 0.0000e+00 - val_loss: 0.0236 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0229 - accuracy: 0.0000e+00 - val_loss: 0.0218 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0213 - accuracy: 0.0000e+00 - val_loss: 0.0202 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0199 - accuracy: 0.0000e+00 - val_loss: 0.0189 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0186 - accuracy: 0.0000e+00 - val_loss: 0.0176 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0174 - accuracy: 0.0000e+00 - val_loss: 0.0165 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0163 - accuracy: 0.0000e+00 - val_loss: 0.0156 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.0000e+00 - val_loss: 0.0147 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0145 - accuracy: 0.0000e+00 - val_loss: 0.0138 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - accuracy: 0.0000e+00 - val_loss: 0.0131 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0129 - accuracy: 0.0000e+00 - val_loss: 0.0124 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0122 - accuracy: 0.0000e+00 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0086 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "Model=model.fit(x_train_scaled,y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "284774a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_predicted=model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "df0f577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2de20ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ad9e8bd1c0>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Model.history['loss'])\n",
    "plt.plot(Model.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c74fcd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
